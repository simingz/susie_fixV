% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/susie.R
\name{susie}
\alias{susie}
\title{SUm of Single Effects (SuSiE) Regression}
\usage{
susie(X, Y, L = min(10, ncol(X)), scaled_prior_variance = 0.2,
  residual_variance = NULL, prior_weights = NULL, null_weight = NULL,
  standardize = TRUE, intercept = TRUE,
  estimate_residual_variance = TRUE, estimate_prior_variance = TRUE,
  estimate_prior_method = c("optim", "EM", "simple"),
  check_null_threshold = 0, prior_tol = 1e-09,
  residual_variance_upperbound = Inf, s_init = NULL, coverage = 0.95,
  min_abs_corr = 0.5, compute_univariate_zscore = FALSE,
  na.rm = FALSE, max_iter = 100, tol = 0.001, verbose = FALSE,
  track_fit = FALSE)
}
\arguments{
\item{X}{An n by p matrix of covariates.}

\item{Y}{A vector of length n.}

\item{L}{Number of components (nonzero elements) in the SuSiE
regression model. If \code{L} is larger than the number of
covariate (p), \code{L} is set to p.}

\item{scaled_prior_variance}{The scaled prior variance. This is
 either a scalar, or a vector of length \code{L}. The prior variance
of each non-zero element of b is set to
\code{var(Y)*scaled_prior_variance}. If
\code{estimate_prior_variance = TRUE}, this input simply provides
initial estimates of the prior variances.}

\item{residual_variance}{The variance of the residual. If
\code{estimate_residual_variance = TRUE}, this value simply provides the
initial estimate of the residual variance. By default, it is set to
\code{var(Y)}.}

\item{prior_weights}{A vector of length p, in which each entry
gives the prior probability that corresponding column of X has a
nonzero effect on the outcome, Y.}

\item{null_weight}{Prior probability of no effect (a number between
0 and 1, and cannot be exactly 1).}

\item{standardize}{If \code{standardize = TRUE}, standardize the
columns of X to unit variance prior to fitting. Note that
`scaled_prior_variance` specifies the prior on the coefficients of
X \emph{after} standardization (if it is performed). If you do not
standardize, you may need to think more carefully about specifying
\code{scaled_prior_variance}. Whatever your choice, the
coefficients returned by \code{coef} are given for \code{X} on the
original input scale. Any column of \code{X} that has zero variance is
not standardized, but left as is.}

\item{intercept}{If \code{intercept = TRUE}, the intercept is
fitted; otherwise, it is set to zero. Setting \code{intercept =
FALSE} is generally not recommended.}

\item{estimate_residual_variance}{If
\code{estimate_residual_variance = TRUE}, the residual variance
is estimated (using \code{residual_variance} as an initial value).
If \code{estimate_residual_variance = FALSE}
then the residual variance is fixed to the value supplied by \code{residual_variance}.}

\item{estimate_prior_variance}{If \code{estimate_prior_variance =
TRUE}, the prior variance is estimated (a separate parameter for each of the \code{L}
effects). If provided, \code{scaled_prior_variance} is then used as an initial
point for the optimization. If \code{estimate_prior_variance = FALSE}
then the prior variance (for each of the \code{L} effects) is determined by the value
supplied to \code{scaled_prior_variance}.}

\item{estimate_prior_method}{The method used for estimating prior
variance. "simple" method only compares the loglikelihood between
using specified prior variance and using zero, and chose the one that
gives larger loglikelihood.}

\item{check_null_threshold}{when prior variance is estimated, compare the
estimate with the null and set prior variance to null (zero) unless the log-likelihood
using the estimate is larger than that of null by this threshold. For example,
you can set it to 0.1 to nudge the estimate towards zero. Default is 0. Notice that setting it to non-zero
may lead to decreasing ELBO in some cases}

\item{prior_tol}{when prior variance is estimated, compare the estimated value to this tol at the end of
the analysis and exclude a single effect from PIP computation if the estimated prior variance is smaller than it.}

\item{residual_variance_upperbound}{Upper bound for estiamted residual variance.
It is used when \code{estimate_residual_variance = TRUE}.}

\item{s_init}{A previous susie fit with which to initialize.}

\item{coverage}{A number between 0 and 1 specifying the coverage of
the estimated confidence sets.}

\item{min_abs_corr}{Minimum of absolute value of correlation
allowed in a credible set. The default, 0.5, corresponds to squared
correlation of 0.25, which is a commonly used threshold for
genotype data in genetics studies.}

\item{compute_univariate_zscore}{If \code{compute_univariate_zscore
= TRUE}, the univariate regression z-scores are outputted for each
variable.}

\item{na.rm}{Drop missing samples in y from both y and X inputs. Default set to FALSE.}

\item{max_iter}{Maximum number of iterations of the IBSS fitting
procedure.}

\item{tol}{A small, non-negative number specifying the convergence
tolerance for the IBSS fitting procedure. The fitting procedure
will halt when the difference in the variational lower bound, or
"ELBO" (this is the objective function to be maximized), is less
than \code{tol}.}

\item{verbose}{If \code{verbose = TRUE}, the algorithm's
progress and a summary of the optimization settings are printed to
the console.}

\item{track_fit}{If \code{track_fit = TRUE}, an object \code{trace}
is also returned containing detailed information about the
estimates at each iteration of the IBSS fitting procedure.}
}
\value{
A \code{"susie"} object with some or all of the following
  elements:

\item{alpha}{An L by p matrix of posterior inclusion probabilites.}

\item{mu}{An L by p matrix of posterior means, conditional on
  inclusion.}

\item{mu2}{An L by p matrix of posterior second moments,
  conditional on inclusion.}

\item{Xr}{An vector of length n, equal to \code{X \%*\% colSums(alpha
  * mu)}.}

\item{intercept}{The intercept (fixed or estimated).}

\item{sigma2}{Residual variance (fixed or estimated).}

\item{V}{Prior variance of the non-zero elements of b, equal to
  \code{scaled_prior_variance * var(Y)}.}

\item{elbo}{The value of the variational lower bound, or "ELBO"
  (the objective function to be maximized), achieved at each
  iteration of the IBSS fitting procedure.}

\item{fitted}{Vector of length n containing the "fitted" values of
  the outcome.}

\item{sets}{Credible sets estimated from model fit; see
  \code{\link{susie_get_cs}} for details.}

\item{pip}{A vector of length p giving the (marginal) posterior
  inclusion probabilities for all p covariates.}

\item{z}{A vector of univariate z-scores.}

\item{niter}{Number of IBSS iterations that were run.}

\item{converged}{\code{TRUE} or \code{FALSE}, indicating whether
  the IBSS converged to a solution within the chosen tolerance
  level.}
}
\description{
Performs Bayesian multiple linear regression of Y on
  X; that is, this function fits the regression model \eqn{Y = sum_l
  Xb_l + e}, where elements of e are \emph{i.i.d.} normal with zero
  mean and variance \code{residual_variance}, and \eqn{sum_l b_l} is
  a vector of length p representing the effects to be estimated. The
  SuSiE assumption is that each b_l has exactly one non-zero
  element. The prior on the non-zero element is normal with zero mean
  and variance \code{var(Y)*scaled_prior_variance}.

  The model is fitted using the "Iterative Bayesian Stepwise
  Selection" (IBSS) algorithm.

  See also \code{susie_trendfilter} for applying susie to non-parametric regression, particularly changepoint problems
}
\examples{

set.seed(1)
n = 1000
p = 1000
beta = rep(0,p)
beta[1:4] = 1
X = matrix(rnorm(n*p),nrow=n,ncol=p)
y = X \%*\% beta + rnorm(n)
res = susie(X,y,L=10)
coef(res)
plot(y,predict(res))

}
\references{
G. Wang, A. Sarkar, P. Carbonetto and M. Stephens (2018). A simple
new approach to variable selection in regression, with application
to genetic fine-mapping. \emph{bioRxiv}
\url{https://doi.org/10.1101/501114}.
}
